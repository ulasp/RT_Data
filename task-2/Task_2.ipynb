{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Урок 2. Парсинг HTML. Библиотека Beautiful soup."
      ],
      "metadata": {
        "id": "4HxJBMejpWPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Необходимо собрать информацию о вакансиях на вводимую должность (используем input или через аргументы получаем должность) с сайтов HH(обязательно) и/или Superjob(по желанию). Приложение должно анализировать несколько страниц сайта (также вводим через input или аргументы). Получившийся список должен содержать в себе минимум:\n",
        "\n",
        "\n",
        "1.   Наименование вакансии.\n",
        "2.   Предлагаемую зарплату (разносим в три поля: минимальная и максимальная и валюта. цифры преобразуем к цифрам).\n",
        "3.   Ссылку на саму вакансию.\n",
        "4.   Сайт, откуда собрана вакансия.\n",
        "\n"
      ],
      "metadata": {
        "id": "gBRrL9cIpmsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение). Структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas. Сохраните в json либо csv.*"
      ],
      "metadata": {
        "id": "2Ue33Bxmp2Qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "from pprint import pprint\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "23XXnyu4qDrd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ссылка (это я для себя ее так перенесла, показалось удобнее :))\n",
        "# https://hh.ru/search/vacancy?\n",
        "# clusters=true&\n",
        "# area=1&\n",
        "# ored_clusters=true&\n",
        "# enable_snippets=true&\n",
        "# salary=&\n",
        "# text=design&\n",
        "# page=3"
      ],
      "metadata": {
        "id": "zdNvs1WhdAsM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field_search = 'design'\n",
        "last_page = 10\n",
        "page = 0\n",
        "\n",
        "params = {'text': field_search,\n",
        "          'page': page}\n",
        "\n",
        "url = 'https://hh.ru/vacancy/'\n",
        "base_url = 'https://hh.ru/search/vacancy?clusters=true&area=1&ored_clusters=true&enable_snippets=true&salary=&'\n",
        "\n",
        "headers = {'user-agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:69.0) Gecko/20100101 Firefox/69.0'}"
      ],
      "metadata": {
        "id": "0cNhesykdK0l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for page in range(last_page):\n",
        "    params['page'] = page\n",
        "    response = requests.get(base_url, params=params, headers=headers)\n",
        "    dom = bs(response.text, 'html.parser')\n",
        "    page = +1"
      ],
      "metadata": {
        "id": "fnPaZukgdS5i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vacancies = dom.find_all('div', {'class': 'vacancy-serp-item-body'})\n",
        "\n",
        "vacancies_list = []\n",
        "for vacancy in vacancies:\n",
        "    vacancy_data = {} # на каждую итерацию будем содавать словарь с данными\n",
        "    vacancy_name = vacancy.find('span', {'class': 'g-user-content'}).getText()\n",
        "    vacancy_link = vacancy.find('a', {'class': 'bloko-link'})['href']\n",
        "    vacancy_company = vacancy.find('div', {'class': 'vacancy-serp-item__meta-info-company'}).getText().replace(u'\\xa0', u' ')\n",
        "    vacancy_city = vacancy.find('div', {'class': 'bloko-text bloko-text_no-top-indent'}).getText()\n",
        "    vacancy_salary = vacancy.find('span', {'class': 'bloko-header-section-3'})\n",
        "    # salary\n",
        "    if vacancy_salary:\n",
        "        vacancy_salary = vacancy_salary.getText().replace('\\xa0', ' ', 3)\n",
        "        vacancy_salary = re.split(r'\\s|-', vacancy_salary)\n",
        "        if vacancy_salary[0] == 'до':\n",
        "            vacancy_salary_min = None\n",
        "            vacancy_salary_max = int(vacancy_salary[1]+vacancy_salary[2])\n",
        "            vacancy_salary_currency = vacancy_salary[3]\n",
        "        elif vacancy_salary[0] == 'от':\n",
        "            vacancy_salary_min = int(vacancy_salary[1]+vacancy_salary[2])\n",
        "            vacancy_salary_max = None\n",
        "            vacancy_salary_currency = vacancy_salary[3]\n",
        "        else:\n",
        "            vacancy_salary_min = int(vacancy_salary[0] + vacancy_salary[1])\n",
        "            vacancy_salary_max = int(vacancy_salary[3] + vacancy_salary[4])\n",
        "            vacancy_salary_currency = vacancy_salary[5]\n",
        "\n",
        "\n",
        "        #print(vacancy_salary[1]+vacancy_salary[2])\n",
        "    else:\n",
        "        vacancy_salary = None\n",
        "        vacancy_salary_min = None\n",
        "        vacancy_salary_max = None\n",
        "        vacancy_salary_currency = None\n",
        "        \n",
        "    vacancy_data['name'] = vacancy_name\n",
        "    vacancy_data['link'] = vacancy_link\n",
        "    vacancy_data['company'] = vacancy_company\n",
        "    vacancy_data['city'] = vacancy_city\n",
        "    vacancy_data['salary_min'] = vacancy_salary_min\n",
        "    vacancy_data['salary_max'] = vacancy_salary_max\n",
        "    vacancy_data['salary_currency'] = vacancy_salary_currency\n",
        "    vacancies_list.append(vacancy_data)\n"
      ],
      "metadata": {
        "id": "83Wdw1oBdp5o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(vacancies_list)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK4hDBvMdupL",
        "outputId": "1a8dd530-93ea-4f1b-ce84-a38f001e35ef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/file.csv')"
      ],
      "metadata": {
        "id": "lnvU9DP9q5kB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "10fa7f84-1232-40b4-a166-3ac4bf2e54b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b379d8d0d242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
          ]
        }
      ]
    }
  ]
}